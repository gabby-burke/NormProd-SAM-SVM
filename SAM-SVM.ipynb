{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9381b629-7c89-4eb8-99b2-d7cdc4c030ad",
   "metadata": {},
   "source": [
    "Steps 2 and 3 of Fast ice detection workflow: SAM, SVM\n",
    "\n",
    "ARE Settings:\n",
    "\n",
    "Queue: gpuvolta\n",
    "Compute size: 1 gpu\n",
    "Jobfs size: 10GB\n",
    "\n",
    "Conda environment: sam_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab7bc0-b6bb-475c-893d-82fd3d6e5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps 2 & 3: SAM + SVM\n",
    "\n",
    "import torch\n",
    "from rasterio.features import rasterize\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box\n",
    "import copy\n",
    "import cv2\n",
    "from scipy.ndimage import zoom\n",
    "import pdb\n",
    "import geopandas as gpd\n",
    "import pathlib\n",
    "import supervision as sv\n",
    "import math\n",
    "from sklearn import svm\n",
    "from pathlib import Path\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio.transform import Affine\n",
    "from scipy.ndimage import minimum_filter1d\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15146d95-7e15-4119-95f5-607a215b53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM 1.1. Enable GPU\n",
    "!nvidia-smi\n",
    "\n",
    "#Set working directory\n",
    "os.chdir('/g/data/jk72/gb4219/honours_data/Normprod_Demo/')\n",
    "#read model weights ('vit_h')\n",
    "CHECKPOINT_PATH = os.path.join(\"/\", \"g\", \"data\", \"jk72\", \"gb4219\", \"honours_data\", \"Normprod_Demo\", \"sam_vit_h_4b8939.pth\")\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "\n",
    "#Model specifications\n",
    "\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\n",
    "\n",
    "############# SAM Parameters, can play with these ####################\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=95,              # High sampling density\n",
    "    pred_iou_thresh=0.85,              # ‚Üì Allow more low-confidence masks\n",
    "    stability_score_thresh=0.85,      # ‚Üì Keep less \"stable\" masks\n",
    "    crop_n_layers=2,                  # ‚Üë Enable multi-resolution crops\n",
    "    crop_n_points_downscale_factor=2, # ‚Üì Fewer points per crop (more diversity)\n",
    "    crop_overlap_ratio=0.5,           # ‚Üë More overlapping regions between crops\n",
    "    box_nms_thresh=0.3,               # ‚Üì Less aggressive suppression of overlapping masks\n",
    "    min_mask_region_area=50,          # ‚Üê Allow tiny segments (don‚Äôt filter small regions)\n",
    "    output_mode='binary_mask' \n",
    ")\n",
    "\n",
    "#function for input image    \n",
    "def fill_nans(image):\n",
    "    \"\"\"Fills NaNs before filtering to prevent them from growing.\"\"\"\n",
    "    nan_mask = np.isnan(image)\n",
    "    if not np.any(nan_mask):\n",
    "        return image\n",
    "    print(\"üîß Filling NaNs before filtering...\")\n",
    "    return np.where(nan_mask, 0, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f850f32-147a-42af-a082-ec0ff3e713dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SAM loop#####\n",
    "\n",
    "# Base directory\n",
    "base_dir = \"/g/data/jk72/gb4219/honours_data/Normprod_Demo/\" ################################################################################\n",
    "# path to coastline shapefile \n",
    "shp_path = pathlib.Path(\"/g/data/jk72/gb4219/honours_data/Normprod_Demo/add_coastline_high_res_polygon_v7_10.shp\")\n",
    "shapefile = gpd.read_file(shp_path)\n",
    " \n",
    "\n",
    "# Loop over every ISCE3 folder\n",
    "for folder_name in sorted(os.listdir(base_dir)):\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue  # skip files, only process directories\n",
    "\n",
    "    print(f\"Processing folder: {folder_name}\")\n",
    "\n",
    "    # Build expected file paths\n",
    "    image_paths = [\n",
    "        os.path.join(folder_path, f\"NormProdSmoVar_11_EPSG3031_{folder_name[-17:]}.tif\"),\n",
    "        os.path.join(folder_path, f\"NormProdSmoVar_21_EPSG3031_{folder_name[-17:]}.tif\"),\n",
    "        os.path.join(folder_path, f\"NormProdSmoVar_33_EPSG3031_{folder_name[-17:]}.tif\"),\n",
    "    ]\n",
    "    \n",
    "    # Load 3 bands\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        with rasterio.open(path) as src:\n",
    "            img = src.read(1)\n",
    "            profile = src.profile\n",
    "            images.append(img)\n",
    "\n",
    "    img1, img2, img3 = images\n",
    "\n",
    "\n",
    "    #Generate landmask (using band 1 as reference)\n",
    "    img_path = pathlib.Path(image_paths[0])\n",
    "    with rasterio.open(img_path) as src:\n",
    "        bounds = src.bounds\n",
    "        xmin, ymin, xmax, ymax = bounds.left, bounds.bottom, bounds.right, bounds.top\n",
    "        width = src.width\n",
    "        height = src.height\n",
    "        transform = rasterio.transform.from_bounds(xmin, ymin, xmax, ymax, width, height)\n",
    "\n",
    "\n",
    "    shapes = ((geom, 1) for geom in shapefile.geometry)\n",
    "    img_landmask = rasterize(\n",
    "        shapes,\n",
    "        out_shape=(height, width),\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        dtype=\"uint8\"\n",
    "    )\n",
    "    print(\"landmask generated\")\n",
    "    \n",
    "    #erode landmask\n",
    "    tmp = minimum_filter1d(img_landmask, size=100, axis=0, mode='constant', cval=0)\n",
    "    eroded_landmask = minimum_filter1d(tmp, size=100, axis=1, mode='constant', cval=0)\n",
    "\n",
    "    print(\"landmask eroded\")\n",
    "\n",
    "\n",
    "    # Normalise (uint8 [0,255])\n",
    "    npmin, npmax, newmax = 0.5, 1.0, 255\n",
    "    img_norm1 = ((img1 + npmin) / (npmax + npmin) * newmax).astype(np.uint8)\n",
    "    img_norm2 = ((img2 + npmin) / (npmax + npmin) * newmax).astype(np.uint8)\n",
    "    img_norm3 = ((img3 + npmin) / (npmax + npmin) * newmax).astype(np.uint8)\n",
    "    print ('normalised three images')\n",
    "\n",
    "\n",
    "    #landmask each img_norm\n",
    "    img_norm1_masked = copy.copy(img_norm1).astype(float)\n",
    "    img_norm1_masked[eroded_landmask==1] = np.nan\n",
    "    \n",
    "    img_norm2_masked = copy.copy(img_norm2).astype(float)\n",
    "    img_norm2_masked[eroded_landmask==1] = np.nan\n",
    "    \n",
    "    img_norm3_masked = copy.copy(img_norm3).astype(float)\n",
    "    img_norm3_masked[eroded_landmask==1] = np.nan\n",
    "\n",
    "\n",
    "    print('masked three images')\n",
    "    \n",
    "    #stack 3 channels into rgb image\n",
    "    img_rgb = cv2.merge([img_norm1_masked, img_norm2_masked, img_norm3_masked])  # shape (H, W, 3)\n",
    "    print('created rgb image')\n",
    "    \n",
    "    #cleanup big files\n",
    "    img1 = img2 = img3 = img_data = img_norm1 = img_norm1_masked = img_norm2 = img_norm2_masked = img_norm3 = img_norm3_masked = 0 \n",
    "    print('cleaned up big files')\n",
    "    \n",
    "    #fill NaNs\n",
    "    img_rgb = fill_nans(img_rgb)\n",
    "\n",
    "    #Downsample by factor of 10\n",
    " \n",
    "    zoom_factors = (1/10, 1/10, 1)  # Downsample 10x on the first two dimensions\n",
    "    resampled = zoom(img_rgb, zoom=zoom_factors, order=1)\n",
    "    resampled = np.nan_to_num(resampled, nan=0)\n",
    "    img_uint8 = (resampled).astype(np.uint8)\n",
    "\n",
    "\n",
    "    #plot RGB and save\n",
    "    plt.imshow(img_uint8/255)\n",
    "    #plt.savefig(\"RGB.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    #plt.savefig(\"RGB.png\", bbox_inches=\"tight\", dpi=300)\n",
    "    #plt.savefig(\"RGB.eps\", bbox_inches=\"tight\")\n",
    "    \n",
    "    print('downsampled')\n",
    "\n",
    "    #Segmentation\n",
    "    sam_result = mask_generator.generate(img_uint8)\n",
    "    print('segmented')\n",
    "    \n",
    "    #visualise segmentation\n",
    "    mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
    "    detections = sv.Detections.from_sam(sam_result=sam_result)\n",
    "    annotated_image = mask_annotator.annotate(scene=img_uint8.copy(), detections=detections)\n",
    "\n",
    "    #Plot rgb image vs segmented image\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    axes[0].imshow(img_uint8)\n",
    "    axes[0].set_title(\"a) source image\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    axes[1].imshow(annotated_image)\n",
    "    axes[1].set_title(\"b) segmented image\")\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save in multiple formats\n",
    "    #fig.savefig(\"SAMmask.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    #fig.savefig(\"SAMmask.pdf\", bbox_inches=\"tight\")\n",
    "    #fig.savefig(\"SAMmask.eps\", bbox_inches=\"tight\")\n",
    "    \n",
    "    #plt.show()\n",
    "    #fig = sv.plot_images_grid(\n",
    "    #    images=[img_uint8, annotated_image],\n",
    "    #    grid_size=(1, 2),\n",
    "    #    titles=['a) source image', 'b)segmented image']\n",
    "    #)\n",
    "    \n",
    "    #fig.savefig(\"SAMmask.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    #fig.savefig(\"SAMmask.pdf\", bbox_inches=\"tight\")\n",
    "    #fig.savefig(\"SAMmask.eps\", bbox_inches=\"tight\")\n",
    "\n",
    "    \n",
    "    #making an array of non-overlapping masks based on 'smallest area wins'\n",
    "    \n",
    "    masks = [\n",
    "        mask['segmentation']\n",
    "        for mask in sorted(sam_result, key=lambda x: x['area'], reverse=True)\n",
    "    ]\n",
    "    height, width = masks[0].shape\n",
    "    label_map = np.zeros((height, width), dtype=np.uint16)\n",
    "    # Compute area for each mask\n",
    "    mask_areas = [np.sum(mask) for mask in masks]\n",
    "    # Get sorted indices: smallest area first\n",
    "    sorted_indices = np.argsort(mask_areas)\n",
    "    # Assign labels: smallest area wins\n",
    "    for label, idx in enumerate(sorted_indices, start=1):\n",
    "        mask = masks[idx]\n",
    "        label_map[np.logical_and(mask, label_map == 0)] = label\n",
    "    \n",
    "    plt.imshow(label_map)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(label_map, cmap='gist_ncar')  \n",
    "    plt.title(\"Segmented Mask ‚Äî Smallest Area Wins\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(label=\"Segment Label\")\n",
    "    #plt.savefig(\"myMasks.pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    #plt.savefig(\"myMasks.png\", bbox_inches=\"tight\", dpi=300)\n",
    "    #plt.savefig(\"myMasks.eps\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    #Write out arrays to segmented_masks\n",
    "    #make output folder specific to scene:\n",
    "    # Extract the date from the filename using a regular expression\n",
    "\n",
    "    date_str = folder_name[-17:]\n",
    "        \n",
    "    folder_name = f'prydz_{date_str}' ############################################################################\n",
    "    # Define the base directory where you want to save the segmented masks \n",
    "    base_directory = '/g/data/jk72/gb4219/honours_data/Normprod_Demo/maps/' ##################################################################\n",
    "    # Create the full path for the new folder\n",
    "    new_folder_path = os.path.join(base_directory, folder_name)\n",
    "    # Create the new folder if it doesn't exist\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "    # Write out segments\n",
    "    output_filepath = os.path.join(new_folder_path, f'label_map_{date_str}.npy')\n",
    "    np.save(output_filepath, label_map)\n",
    "    #write out rgb image\n",
    "    output_filepath = os.path.join(new_folder_path, f'rgb_image_{date_str}.npy')\n",
    "    np.save(output_filepath, img_uint8)\n",
    "    print('files written out')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2e4a4-aaca-4d15-93fc-88c82c9c69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM \n",
    "\n",
    "#directory of labelled scenes to train the SVM\n",
    "TRAIN_DATA_DIR = pathlib.Path('/g/data/jk72/gb4219/honours_data/SVM_trainingdata/')###########\n",
    "\n",
    "# list of all images that should be used for training\n",
    "# these folder are located in the DATA_DIR that I defined above\n",
    "training_image_list = [\n",
    "    'prydz_20210129_20210210',\n",
    "    'prydz_20210330_20210411',\n",
    "    'prydz_20210728_20210809',\n",
    "    'prydz_20210821_20210902',\n",
    "    'prydz_20211020_20211101',\n",
    "    'thwaites_20240708_20240720',\n",
    "    'thwaites_20240813_20240825',\n",
    "    'thwaites_20241012_20241024',\n",
    "    'thwaites_20241024_20241105',\n",
    "    'thwaites_20241105_20241117'\n",
    "    \n",
    "]\n",
    "# initialize an empty training feature and label vector\n",
    "# we will append the training data extracted from each segment to these\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# we have 4 class labels\n",
    "class_label_list = [0,2,3]\n",
    "\n",
    "# assign 4 class colors\n",
    "class_color_list = [\n",
    "    [1,0,0],\n",
    "    [0,1,0],\n",
    "    [0,0,1],\n",
    "    [0,0,0]\n",
    "]\n",
    "\n",
    "for img in training_image_list:\n",
    "\n",
    "    print(f'Processing image {img}')\n",
    "\n",
    "    img_date = f'{img.split('_')[1]}_{img.split('_')[2]}'\n",
    "\n",
    "    print(f'img_date: {img_date}')\n",
    "    \n",
    "    # build the full paths to the files we need\n",
    "    RGB_path     = TRAIN_DATA_DIR / img / f'rgb_image_{img_date}.npy'\n",
    "    segment_path = TRAIN_DATA_DIR / img / f'label_map_{img_date}.npy'\n",
    "    labels_path  = TRAIN_DATA_DIR / img / f'labelled_array_{img_date}.npy'\n",
    "\n",
    "    # read in data from current img\n",
    "    rgb            = np.load(RGB_path)\n",
    "    segments       = np.load(segment_path)\n",
    "    segment_labels = np.load(labels_path)\n",
    "\n",
    "    # loop over all segments in your current img\n",
    "    for current_segment in np.unique(segments):\n",
    "        #print(f'Processing segment number {current_segment}')\n",
    "\n",
    "        # get class label of current segment\n",
    "        current_segment_label = segment_labels[current_segment]\n",
    "\n",
    "        #print(f'    Current segment class label: {current_segment_label}')\n",
    "\n",
    "        # only use the segment if its label is other than nan\n",
    "        if not np.isnan(current_segment_label):\n",
    "           # print('    Using this segment')\n",
    "\n",
    "            # get the NP data (here: normalized in RGB) for current segment\n",
    "            current_segment_data = rgb[segments==current_segment]\n",
    "\n",
    "            # and average them to one single training vector for the current segment\n",
    "            current_X_train = current_segment_data.mean(0)\n",
    "\n",
    "\n",
    "            #print(f'    Current training feature vector: {current_X_train}')\n",
    "\n",
    "            # now append the current segment to the training feature and label vecor\n",
    "            X_train.append(list(current_X_train))\n",
    "            y_train.append(int(current_segment_label))\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "#visualise training dataset\n",
    "#fig, ax = plt.subplots(1,1)\n",
    "#for class_label in class_label_list:\n",
    "#    ax.plot(\n",
    "#        X_train[y_train==class_label,1],\n",
    "#        X_train[y_train==class_label,2],\n",
    "#        '.',\n",
    "#        color=class_color_list[class_label]\n",
    "#)\n",
    "#ax.legend(['Pack/ocean ', 'Class 2=fast', 'Class 3 = melting fast ice'])\n",
    "#ax.set_xlabel(\"Average pixel value (dimension 1)\")   \n",
    "#ax.set_ylabel(\"Average pixel value (dimension 2)\")\n",
    "#plt.show()\n",
    "\n",
    "# Base directory containing test folders\n",
    "TEST_DATA_DIR = Path(\"/g/data/jk72/gb4219/honours_data/Normprod_Demo/maps/\")######################################################################\n",
    "\n",
    "# Build set of training dates to skip\n",
    "training_dates = set()\n",
    "for img in training_image_list:\n",
    "    date_str = f\"{img.split('_')[1]}_{img.split('_')[2]}\"\n",
    "    training_dates.add(date_str)\n",
    "\n",
    "# Initialize lists\n",
    "X_test = []\n",
    "test_segments_info = []\n",
    "\n",
    "# Loop over all folders in TEST_DATA_DIR\n",
    "for folder in sorted(TEST_DATA_DIR.iterdir()):\n",
    "    if not folder.is_dir():\n",
    "        continue\n",
    "\n",
    "    # Find the label_map file in the folder\n",
    "    label_files = list(folder.glob(\"label_map_*.npy\"))\n",
    "    if len(label_files) == 0:\n",
    "        print(f\"‚ö†Ô∏è No label_map found in {folder}, skipping\")\n",
    "        continue\n",
    "\n",
    "    label_file = label_files[0]  # take the first one if multiple exist\n",
    "\n",
    "    # Extract date string from filename\n",
    "    import re\n",
    "    match = re.search(r'label_map_(\\d{8}_\\d{8})\\.npy$', label_file.name)\n",
    "    if not match:\n",
    "        print(f\"‚ö†Ô∏è Could not extract date from {label_file.name}, skipping\")\n",
    "        continue\n",
    "    date_str = match.group(1)\n",
    "\n",
    "    # Skip if date in training dataset\n",
    "    #if date_str in training_dates:\n",
    "        #print(f\"Skipping {folder.name}, date {date_str} in training set\")\n",
    "        #continue\n",
    "\n",
    "    # Build RGB path in the same folder\n",
    "    rgb_file = folder / f\"rgb_image_{date_str}.npy\"\n",
    "    if not rgb_file.exists():\n",
    "        print(f\"‚ö†Ô∏è No RGB file found at {rgb_file}, skipping\")\n",
    "        continue\n",
    "\n",
    "    # Load data\n",
    "    segments = np.load(label_file)\n",
    "    rgb = np.load(rgb_file)\n",
    "\n",
    "    # Extract features from segments\n",
    "    for seg_id in np.unique(segments):\n",
    "        seg_data = rgb[segments == seg_id]\n",
    "        feature_vec = seg_data.mean(0)\n",
    "        X_test.append(feature_vec.tolist())\n",
    "        test_segments_info.append((folder.name, int(seg_id)))\n",
    "\n",
    "# Convert to numpy array\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "# Apply model\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "#####Save prediction map output ####\n",
    "\n",
    "\n",
    "# Group predictions by image\n",
    "predictions_by_image = {}\n",
    "\n",
    "for (img_name, seg_id), pred_class in zip(test_segments_info, y_test_pred):\n",
    "    if img_name not in predictions_by_image:\n",
    "        predictions_by_image[img_name] = {}\n",
    "    predictions_by_image[img_name][seg_id] = pred_class\n",
    "\n",
    "# Now reconstruct a map for each image\n",
    "for img_name, seg_predictions in predictions_by_image.items():\n",
    "\n",
    "    img_date = f'{img_name.split(\"_\")[1]}_{img_name.split(\"_\")[2]}'\n",
    "\n",
    "    # Path to this image's folder in TEST_DATA_DIR\n",
    "    out_dir = TEST_DATA_DIR / img_name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)  # just in case\n",
    "\n",
    "    # Load segments\n",
    "    segment_path = out_dir / f'label_map_{img_date}.npy'\n",
    "    segments = np.load(segment_path)\n",
    "\n",
    "    # Create empty prediction map\n",
    "    pred_map = np.zeros_like(segments, dtype=int)\n",
    "\n",
    "    # Fill each segment with predicted class\n",
    "    for seg_id, pred_class in seg_predictions.items():\n",
    "        pred_map[segments == seg_id] = pred_class\n",
    "\n",
    "    \"\"\"\n",
    "    height, width = pred_map.shape\n",
    "    new_transform = rasterio.transform.from_bounds(xmin, ymin, xmax, ymax, width, height)\n",
    "    \n",
    "    second_landmask = rasterize(\n",
    "        shapes,\n",
    "        out_shape=(height, width),\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        dtype=\"uint8\"\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    REF_BASE = Path(\"/g/data/jk72/gb4219/honours_data/Normprod_Demo/\")#######################################################################\n",
    "    \n",
    "    ref_folder = REF_BASE / f\"ISCE3_NormProd_EW_{img_date}\"\n",
    "    ref_path = ref_folder / f\"NormProdSmoVar_11_EPSG3031_{img_date}.tif\"\n",
    "\n",
    "    if not ref_path.exists():\n",
    "    # fallback: try to find a close match inside the folder\n",
    "        candidates = list(ref_folder.glob(f\"NormProdSmoVar_11*{img_date}*.tif\"))\n",
    "        if not candidates:\n",
    "            print(f\"‚ö†Ô∏è No reference tif found for {img_date} in {ref_folder}; skipping GeoTIFF.\")\n",
    "        else:\n",
    "            ref_path = candidates[0]\n",
    "\n",
    "    if ref_path.exists():\n",
    "        with rasterio.open(ref_path) as src:\n",
    "            profile = src.profile.copy()\n",
    "            T = src.transform\n",
    "    \n",
    "    # --- Open reference raster (defines grid, transform, CRS) ---\n",
    "    with rasterio.open(ref_path) as src:\n",
    "        ref_shape = (src.height, src.width)\n",
    "        ref_transform = src.transform\n",
    "        ref_crs = src.crs\n",
    "        profile = src.profile.copy()\n",
    "    \n",
    "    # --- Rasterize landmask from shapefile ---\n",
    "    gdf = gpd.read_file(\"/g/data/jk72/gb4219/honours_data/Normprod_Demo/add_coastline_high_res_polygon_v7_10.shp\")\n",
    "    \n",
    "    if gdf.crs is None:\n",
    "        gdf = gdf.set_crs(\"EPSG:3031\")  # replace with actual CRS if needed\n",
    "    if gdf.crs != ref_crs:\n",
    "        gdf = gdf.to_crs(ref_crs)\n",
    "    \n",
    "    landmask_resampled = rasterize(\n",
    "        [(geom, 1) for geom in gdf.geometry],\n",
    "        out_shape=ref_shape,\n",
    "        transform=ref_transform,\n",
    "        fill=0,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "    \n",
    "    # --- Upsample pred_map to reference size safely ---\n",
    "    pred_map_resized = resize(\n",
    "        pred_map,\n",
    "        ref_shape,             # target height, width\n",
    "        order=0,               # nearest neighbor preserves classes\n",
    "        preserve_range=True,    # keep original class IDs\n",
    "        anti_aliasing=False\n",
    "    ).astype(np.uint8)\n",
    "    \n",
    "    # --- Apply landmask ---\n",
    "    pred_map_masked = pred_map_resized.copy()\n",
    "    pred_map_masked[landmask_resampled == 1] = 1  # or 255/nodata if preferred\n",
    "    \n",
    "    # --- Save a quicklook PNG ---\n",
    "    class_colors = np.array([\n",
    "        [255,   0,   0],   # class 0 ‚Üí red\n",
    "        [  0, 255,   0],   # class 1 ‚Üí green\n",
    "        [  0,   0, 255],   # class 2 ‚Üí blue\n",
    "        [  0,   0,   0],   # class 3 ‚Üí black\n",
    "        [200, 200, 200],   # land (masked) ‚Üí grey\n",
    "    ], dtype=np.uint8)\n",
    "    \n",
    "    rgb_pred_map = class_colors[np.where(pred_map_masked == 1, 4, pred_map_masked)]\n",
    "    plt.imsave(out_dir / f'predicted_map_{img_date}.png', rgb_pred_map)\n",
    "    \n",
    "    # --- Save georeferenced GeoTIFF ---\n",
    "    profile.update(\n",
    "        dtype=rasterio.uint8,\n",
    "        count=1,\n",
    "        height=ref_shape[0],\n",
    "        width=ref_shape[1],\n",
    "        transform=ref_transform,\n",
    "        crs=ref_crs,\n",
    "        compress='lzw',\n",
    "        nodata=255\n",
    "    )\n",
    "    \n",
    "    geotiff_path = out_dir / f'predicted_map_{img_date}.tif'\n",
    "    with rasterio.open(geotiff_path, 'w', **profile) as dst:\n",
    "        dst.write(pred_map_masked, 1)\n",
    "    \n",
    "    print(f\"‚úÖ Saved georeferenced prediction for {img_name} to {geotiff_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
