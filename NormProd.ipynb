{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c329ca1e-3df7-41af-905e-db0db854d1aa",
   "metadata": {},
   "source": [
    "Step 1 of Fast ice detection workflow: Normalised Product\n",
    "\n",
    "ARE Settings:\n",
    "\n",
    "Queue: Normal\n",
    "Compute size: Medium\n",
    "Jobfs size: 10GB\n",
    "\n",
    "Requires process_image_pairs.py\n",
    "\n",
    "Conda environment: sam_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0bb0cf2-b54f-4157-90f3-c310070ae8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup \n",
    "#Step1: Normprod Step\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import yaml\n",
    "import shutil\n",
    "from shapely import Polygon, box\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import rasterio\n",
    "import rasterio.merge\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "#import Tony_FastIce24\n",
    "import json\n",
    "import subprocess\n",
    "from osgeo import gdal,ogr,osr,gdal_array, gdalconst\n",
    "gdal.UseExceptions()\n",
    "import scipy.ndimage\n",
    "from scipy.ndimage import uniform_filter#, convolve   # ALEX ADDED THIS to get the local SD within the kernel\n",
    "from scipy.ndimage import gaussian_filter, generic_filter  # And chat added this because it's faster than the two above\n",
    "import pdb #for debugging.\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import psutil\n",
    "import sys\n",
    "import ast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae5084e-adfc-4ed8-b53d-c8f868cb3818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Memory usage: 572.05 MB\n",
      "Finding whole stack intersection\n",
      "/g/data/jk72/gb4219/honours_data/Normprod_Demo/S1A__EW___A_20210716T152833_HH_grd_mli_gamma0-rtc_geo_db_3031.tif\n",
      "/g/data/jk72/gb4219/honours_data/Normprod_Demo/S1A__EW___A_20210728T152834_HH_grd_mli_gamma0-rtc_geo_db_3031.tif\n",
      "Determined maximal (union) stack bounds. [1815744.144, 1155865.665, 2606917.871, 374040.5]\n",
      "End: Memory usage: 572.30 MB\n"
     ]
    }
   ],
   "source": [
    "#Normprod 1.1\n",
    "## THIS IS FOR CAITLIN EWs - and doing the FULL STACK\n",
    "### calculate maximal bounds for whole stack for a common projection geot. \n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "memory_usage = process.memory_info().rss / (1024 ** 2)  # Convert bytes to MB\n",
    "print(f\"Start: Memory usage: {memory_usage:.2f} MB\")\n",
    "\n",
    "useWholeStack = True   #   else use pair.\n",
    "findOuterBounds = True   # ie. union,  else innerBounds, ie. intersection.\n",
    "\n",
    "localDataDir = os.path.join('/','g','data','jk72','gb4219','honours_data','Normprod_Demo') ########## EW DIRECTORY HERE ############\n",
    "\n",
    "searchstring = \"_3031.tif\"  ########### Read files with this suffix (sometimes Caitlin changes them) ########\n",
    "\n",
    "full_filenames = sorted([f for f in Path(localDataDir).iterdir() if f.is_file() and searchstring in f.name])\n",
    "base_filenames = [f.name for f in full_filenames]\n",
    "\n",
    "startXs = []\n",
    "endXs = []\n",
    "deltaXs = []\n",
    "startYs = []\n",
    "endYs = []\n",
    "deltaYs = []\n",
    "if useWholeStack:\n",
    "    useRange = range(len(base_filenames))\n",
    "    print(\"Finding whole stack intersection\")\n",
    "else:\n",
    "    useRange = imPair\n",
    "    print(\"Finding pair intersection\")\n",
    "for which in useRange: # Want to find common bounds for whole stack.\n",
    "    #pdb.set_trace()\n",
    "    geoGRDi = os.path.join(localDataDir, base_filenames[which])\n",
    "    print(geoGRDi)\n",
    "    if os.path.exists(geoGRDi):\n",
    "        #check extents overlap and crop to intersection with gdal.Warp\n",
    "        DSi = gdal.Open(geoGRDi, gdal.GA_ReadOnly)\n",
    "        NXi, NYi, NBi = DSi.RasterXSize, DSi.RasterYSize, DSi.RasterCount\n",
    "        geoti = DSi.GetGeoTransform()\n",
    "        startXs.append(geoti[0])\n",
    "        endXs.append(geoti[0]+geoti[1]*NXi)\n",
    "        startYs.append(geoti[3])\n",
    "        endYs.append(geoti[3]+geoti[5]*NYi)  # NB. geoti[5] is -ve.\n",
    "        deltaXs.append(geoti[1])\n",
    "        deltaYs.append(geoti[5])\n",
    "        geoti = None\n",
    "        DSi = None\n",
    "# should find actual data extent, not just image bounds. Need to get inside arrays looking for non-NaN extents.\n",
    "#  For now, just let the compression reduce the file size and leave the actual extent.\n",
    "#  [X0 P.dx L.dy Y0 P.dx L.dy]\n",
    "\n",
    "if findOuterBounds:\n",
    "    newX0 = min(startXs)\n",
    "    newPdx = sum(deltaXs)/len(deltaXs)\n",
    "    newY0 = max(startYs)\n",
    "    newLdy = sum(deltaYs)/len(deltaYs)\n",
    "    endX = max(endXs)\n",
    "    endY = min(endYs)  # NB: Y-axis goes negative direction\n",
    "    stackBounds = (newX0, newY0, endX, endY)\n",
    "    print(\"Determined maximal (union) stack bounds.\", [round(e, 3) for e in stackBounds])\n",
    "else:\n",
    "    #pdb.set_trace()\n",
    "    newX0 = max(startXs)\n",
    "    newPdx = sum(deltaXs)/len(deltaXs)\n",
    "    newY0 = min(startYs)\n",
    "    newLdy = sum(deltaYs)/len(deltaYs)\n",
    "    endX = min(endXs)\n",
    "    endY = max(endYs)  # NB: Y-axis goes negative direction\n",
    "    stackBounds = (newX0, newY0, endX, endY)\n",
    "    print(\"Determined minimal (intersection) stack bounds.\", [round(e, 3) for e in stackBounds])\n",
    "newgeot = [newX0, newPdx, 0, newY0, 0, newLdy]\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "memory_usage = process.memory_info().rss / (1024 ** 2)  # Convert bytes to MB\n",
    "print(f\"End: Memory usage: {memory_usage:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9adfb6-f6f4-4e19-9135-f4519b6a4a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair:\n",
      "\tS1A__EW___A_20210716T152833_HH_grd_mli_gamma0-rtc_geo_db_3031.tif\n",
      "\tS1A__EW___A_20210728T152834_HH_grd_mli_gamma0-rtc_geo_db_3031.tif\n",
      "‚úÖ Data-sets already trimmed.\n",
      "All valid pairs within threshold: [[0, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Normprod 1.2. Overlap-trimming\n",
    "# this is where we can choose a temporal baseline \n",
    "# and trim image pairs to their overlapping area if baseline is less or more than a repeat pass\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "import psutil\n",
    "from osgeo import gdal, osr\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize EPSG 3031 projection\n",
    "outputEPSG = 3031\n",
    "Psrs = osr.SpatialReference()\n",
    "Psrs.ImportFromEPSG(outputEPSG)\n",
    "\n",
    "# Function to extract date from filename\n",
    "def extract_date(filename):\n",
    "    return datetime.strptime(filename[12:20], \"%Y%m%d\")\n",
    "\n",
    "# threshold_days = 2  # Maximum allowed separation in days #####################################\n",
    "threshold_min = 11.9\n",
    "threshold_max = 12.1\n",
    "allPairs = []  # Store valid pairs\n",
    "\n",
    "def get_valid_data_extent(ds):\n",
    "    \"\"\"Compute the bounding box of the valid (non-NaN) data in a GDAL dataset.\"\"\"\n",
    "    band = ds.GetRasterBand(1)\n",
    "    nodata = band.GetNoDataValue()\n",
    "    \n",
    "    arr = band.ReadAsArray()\n",
    "    \n",
    "    # Create a valid mask: Exclude nodata and NaN values\n",
    "    if nodata is not None:\n",
    "        mask = (arr != nodata) & ~np.isnan(arr)\n",
    "    else:\n",
    "        mask = ~np.isnan(arr)  # Assuming float data with NaNs\n",
    "\n",
    "    if not np.any(mask):  # No valid data\n",
    "        return None\n",
    "\n",
    "    # Get min/max row/col indices where data is valid\n",
    "    row_indices = np.where(np.any(mask, axis=1))[0]\n",
    "    col_indices = np.where(np.any(mask, axis=0))[0]\n",
    "\n",
    "    if row_indices.size == 0 or col_indices.size == 0:\n",
    "        return None  # No valid pixels found\n",
    "\n",
    "    min_row, max_row = row_indices[0], row_indices[-1]\n",
    "    min_col, max_col = col_indices[0], col_indices[-1]\n",
    "\n",
    "    # Convert pixel coordinates to geographic coordinates\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    xRes, yRes = abs(geotransform[1]), abs(geotransform[5])  # Pixel size\n",
    "    min_x = geotransform[0] + geotransform[1] * min_col\n",
    "    max_x = geotransform[0] + geotransform[1] * (max_col + 1)\n",
    "    max_y = geotransform[3] + geotransform[5] * min_row\n",
    "    min_y = geotransform[3] + geotransform[5] * (max_row + 1)\n",
    "\n",
    "    return (min_x, min_y, max_x, max_y, xRes, yRes)\n",
    "\n",
    "\n",
    "# Iterate over all unique image pairs\n",
    "for i in range(len(base_filenames)):\n",
    "    for j in range(i + 1, len(base_filenames)):\n",
    "        base1 = base_filenames[i]\n",
    "        base2 = base_filenames[j]\n",
    "        \n",
    "        date1 = extract_date(base1)\n",
    "        date2 = extract_date(base2)\n",
    "        \n",
    "       # if abs((date1 - date2).days) > threshold_days:\n",
    "\n",
    "        if not (threshold_min <= abs((date1 - date2).days) <= threshold_max):\n",
    "            print('skipping this pair because separation was ' + str(abs((date1 - date2).days)))\n",
    "            continue  # Skip pairs with a separation greater than threshold\n",
    "        \n",
    "        allPairs.append([i, j])  # Store valid pair indices\n",
    "        \n",
    "        geoGRD1 = os.path.join(localDataDir, base1)\n",
    "        geoGRD2 = os.path.join(localDataDir, base2)\n",
    "\n",
    "        if os.path.exists(geoGRD1) and os.path.exists(geoGRD2):\n",
    "            print(\"Processing pair:\")\n",
    "            print(f\"\\t{base1}\")\n",
    "            print(f\"\\t{base2}\")\n",
    "            \n",
    "            compareFold = os.path.join(localDataDir, f\"ISCE3_NormProd_EW_{date1.strftime('%Y%m%d')}_{date2.strftime('%Y%m%d')}\")\n",
    "            os.makedirs(compareFold, exist_ok=True)\n",
    "            \n",
    "            DS1 = gdal.Open(geoGRD1, gdal.GA_ReadOnly)\n",
    "            DS2 = gdal.Open(geoGRD2, gdal.GA_ReadOnly)\n",
    "            \n",
    "            georeg1 = os.path.join(compareFold, f\"georeg_1_{date1.strftime('%Y%m%d')}_EPSG{outputEPSG}.tif\")\n",
    "            georeg2 = os.path.join(compareFold, f\"georeg_2_{date2.strftime('%Y%m%d')}_EPSG{outputEPSG}.tif\")\n",
    "            justMade = False\n",
    "\n",
    "            extent1 = get_valid_data_extent(DS1)\n",
    "            extent2 = get_valid_data_extent(DS2)\n",
    "            \n",
    "            \n",
    "            # Compute the INTERSECTION of the extents\n",
    "            if extent1 and extent2:\n",
    "                min_x = max(extent1[0], extent2[0])  # Max of min_x\n",
    "                min_y = max(extent1[1], extent2[1])  # Max of min_y\n",
    "                max_x = min(extent1[2], extent2[2])  # Min of max_x\n",
    "                max_y = min(extent1[3], extent2[3])  # Min of max_y\n",
    "                xRes = min(extent1[4], extent2[4])  # Use the finer resolution\n",
    "                yRes = min(extent1[5], extent2[5])  \n",
    "\n",
    "                \n",
    "                # Check if valid intersection exists\n",
    "                if min_x >= max_x or min_y >= max_y:\n",
    "                    print(f\"‚ùå No overlapping region between {base1} and {base2}. Skipping.\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"‚ùå One of the images is fully NaN. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            if not (os.path.exists(georeg1) and os.path.exists(georeg2)):\n",
    "                gdal.Warp(georeg1, DS1, format=\"GTiff\", dstSRS=Psrs, outputBounds=(min_x, min_y, max_x, max_y), \n",
    "                          xRes=xRes, yRes=yRes, dstNodata=np.nan, \n",
    "                          outputType=gdal.GDT_Float32, creationOptions=[\"COMPRESS=DEFLATE\", \"BIGTIFF=YES\"])\n",
    "                gdal.Warp(georeg2, DS2, format=\"GTiff\", dstSRS=Psrs, outputBounds=(min_x, min_y, max_x, max_y), \n",
    "                          xRes=xRes, yRes=yRes, dstNodata=np.nan, \n",
    "                          outputType=gdal.GDT_Float32, creationOptions=[\"COMPRESS=DEFLATE\", \"BIGTIFF=YES\"])\n",
    "                justMade = True\n",
    "\n",
    "            DS1, DS2 = None, None\n",
    "            \n",
    "            if os.path.exists(georeg1) and os.path.exists(georeg2):\n",
    "                if justMade:\n",
    "                    print(\"Masked non-overlapping parts with NaNs.\")\n",
    "                    DS1 = gdal.Open(georeg1, gdal.GA_Update)\n",
    "                    DS2 = gdal.Open(georeg2, gdal.GA_Update)\n",
    "                    Dat1, Dat2 = DS1.ReadAsArray(), DS2.ReadAsArray()\n",
    "                    \n",
    "                    NBnds1, NBnds2 = DS1.RasterCount, DS2.RasterCount\n",
    "                    if NBnds1 == 1:\n",
    "                        Dat1 = np.expand_dims(Dat1, 0)\n",
    "                    if NBnds2 == 1:\n",
    "                        Dat2 = np.expand_dims(Dat2, 0)\n",
    "\n",
    "                    Intersection = ~np.isnan(Dat1[0]) & ~np.isnan(Dat2[0])\n",
    "                    if NBnds1 > 1:\n",
    "                        Intersection &= ~np.isnan(Dat1[1]) & ~np.isnan(Dat2[1])\n",
    "\n",
    "                    for di in range(NBnds1):\n",
    "                        Dat1[di][~Intersection] = np.nan\n",
    "                        Bnd1 = DS1.GetRasterBand(di+1)\n",
    "                        Bnd1.WriteArray(np.float32(Dat1[di]))\n",
    "                        Bnd1.SetNoDataValue(np.nan)\n",
    "                        Bnd1.FlushCache()\n",
    "                        \n",
    "                        Dat2[di][~Intersection] = np.nan\n",
    "                        Bnd2 = DS2.GetRasterBand(di+1)\n",
    "                        Bnd2.WriteArray(np.float32(Dat2[di]))\n",
    "                        Bnd2.SetNoDataValue(np.nan)\n",
    "                        Bnd2.FlushCache()\n",
    "\n",
    "                    DS1.FlushCache()\n",
    "                    DS1 = None\n",
    "                    DS2.FlushCache()\n",
    "                    DS2 = None\n",
    "                    print(\"‚úÖ Trimmed to overlapping area.\")\n",
    "                else:\n",
    "                    print(\"‚úÖ Data-sets already trimmed.\")\n",
    "            else:\n",
    "                print(\"‚ùå Failed to co-register inputs.\")\n",
    "        else:\n",
    "            print(\"‚ùå Missing some input files.\")\n",
    "\n",
    "DS1 = None\n",
    "DS2 = None\n",
    "gc.collect()\n",
    "\n",
    "print(\"All valid pairs within threshold:\", allPairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888525bd-99cb-45b2-b468-2eb5f7e306b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normprod  1.3. Define Normprod functions\n",
    "#This doesn't do the actual normprod algorithms - but it defines them in functions\n",
    "\n",
    "# PARAMETERS\n",
    "windows = [11, 21, 33]  # Gaussian smoothing levels\n",
    "\n",
    "def check_raster_stats(filepath):\n",
    "    \"\"\"Prints min, max, mean, and std of a raster file.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"‚ùå ERROR: {filepath} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    ds = gdal.Open(filepath, gdal.GA_ReadOnly)\n",
    "    if ds is None:\n",
    "        print(f\"‚ùå ERROR: Cannot open {filepath}\")\n",
    "        return\n",
    "    \n",
    "    arr = ds.GetRasterBand(1).ReadAsArray()\n",
    "    print(f\"üìä Stats for {filepath}:\")\n",
    "    print(f\"  Min: {np.nanmin(arr)}\")\n",
    "    print(f\"  Max: {np.nanmax(arr)}\")\n",
    "    print(f\"  Mean: {np.nanmean(arr)}\")\n",
    "    print(f\"  Std Dev: {np.nanstd(arr)}\\n\")\n",
    "    ds = None\n",
    "\n",
    "def fill_nans(image):\n",
    "    \"\"\"Fills NaNs before filtering to prevent them from growing.\"\"\"\n",
    "    nan_mask = np.isnan(image)\n",
    "    \n",
    "    if not np.any(nan_mask):  # If no NaNs, return original\n",
    "        return image\n",
    "\n",
    "    print(\"üîß Filling NaNs before filtering...\")\n",
    "\n",
    "    # Simple approach: replace NaNs with the local mean of valid pixels\n",
    "    mean_value = np.nanmean(image)\n",
    "    image_filled = np.where(nan_mask, mean_value, image)\n",
    "\n",
    "    return image_filled\n",
    "\n",
    "# DoG is waaaaay wider than sigma. Like if sigma is 11 is goes out to like 33... Bad effects on the Tony algorithm. \n",
    "def compute_dog(image_path, output_path, sigma):\n",
    "    \"\"\"Computes the Difference of Gaussians (DoG) while preventing NaN spread.\"\"\"\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"‚úÖ Skipping, {output_path} already exists.\")\n",
    "        return output_path\n",
    "\n",
    "    ds = gdal.Open(image_path, gdal.GA_ReadOnly)\n",
    "    if ds is None:\n",
    "        print(f\"‚ùå ERROR: Cannot open {image_path}\")\n",
    "        return None\n",
    "\n",
    "    driver = gdal.GetDriverByName(\"GTIFF\")\n",
    "\n",
    "    # Read the single-band raster\n",
    "    band = ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "    # Fill NaNs before applying Gaussian filter\n",
    "    band_filled = fill_nans(band)\n",
    "\n",
    "    # Compute Gaussian smoothing on the filled data\n",
    "    smoothed = gaussian_filter(band_filled, sigma=sigma)\n",
    "\n",
    "    # DoG = Original - Smoothed\n",
    "    dog = band - smoothed\n",
    "\n",
    "    # Save DoG image\n",
    "    out_ds = driver.Create(output_path, ds.RasterXSize, ds.RasterYSize, 1, gdal.GDT_Float32,\n",
    "                           options=[\"COMPRESS=DEFLATE\", \"BIGTIFF=YES\"])\n",
    "    out_ds.SetGeoTransform(ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(ds.GetProjection())\n",
    "    out_ds.GetRasterBand(1).WriteArray(dog)\n",
    "    out_ds.GetRasterBand(1).SetNoDataValue(np.nan)\n",
    "    out_ds.FlushCache()\n",
    "    out_ds = None\n",
    "\n",
    "    ds = None\n",
    "    print(f\"‚úÖ Saved DoG image: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# Hmmmm it seems DoG is quite different from Tony's original boxcar.... Let's define a boxcar filter too.\n",
    "def compute_boxcar_diff(image_path, output_path, width):\n",
    "    \"\"\"Computes the difference from 2D boxcar smoothing (boxcar DoG-like) while preventing NaN spread.\"\"\"\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"‚úÖ Skipping, {output_path} already exists.\")\n",
    "        return output_path\n",
    "\n",
    "    ds = gdal.Open(image_path, gdal.GA_ReadOnly)\n",
    "    if ds is None:\n",
    "        print(f\"‚ùå ERROR: Cannot open {image_path}\")\n",
    "        return None\n",
    "\n",
    "    driver = gdal.GetDriverByName(\"GTIFF\")\n",
    "\n",
    "    band = ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "    # Fill NaNs before filtering\n",
    "    band_filled = fill_nans(band)\n",
    "\n",
    "    # Apply 2D boxcar filter\n",
    "    smoothed = uniform_filter(band_filled, size=width, mode=\"nearest\")\n",
    "\n",
    "    # Difference from smoothed version\n",
    "    diff = band - smoothed\n",
    "\n",
    "    # Save result\n",
    "    out_ds = driver.Create(output_path, ds.RasterXSize, ds.RasterYSize, 1, gdal.GDT_Float32,\n",
    "                           options=[\"COMPRESS=DEFLATE\", \"BIGTIFF=YES\"])\n",
    "    out_ds.SetGeoTransform(ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(ds.GetProjection())\n",
    "    out_ds.GetRasterBand(1).WriteArray(diff)\n",
    "    out_ds.GetRasterBand(1).SetNoDataValue(np.nan)\n",
    "    out_ds.FlushCache()\n",
    "    out_ds = None\n",
    "\n",
    "    ds = None\n",
    "    print(f\"‚úÖ Saved boxcar diff image: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def compute_local_std(image_path, output_path, width):\n",
    "    \"\"\"Computes the local standard deviation in a boxcar window of given width.\"\"\"\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"‚úÖ Skipping, {output_path} already exists.\")\n",
    "        return output_path\n",
    "\n",
    "    ds = gdal.Open(image_path, gdal.GA_ReadOnly)\n",
    "    if ds is None:\n",
    "        print(f\"‚ùå ERROR: Cannot open {image_path}\")\n",
    "        return None\n",
    "\n",
    "    driver = gdal.GetDriverByName(\"GTIFF\")\n",
    "\n",
    "    band = ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "    # Fill NaNs before filtering\n",
    "    band_filled = fill_nans(band)\n",
    "\n",
    "    # Compute mean and mean of squares in local window\n",
    "    local_mean = uniform_filter(band_filled, size=width, mode=\"nearest\")\n",
    "    local_mean_sq = uniform_filter(band_filled**2, size=width, mode=\"nearest\")\n",
    "\n",
    "    # Standard deviation: sqrt(E[x^2] - (E[x])^2)\n",
    "    local_std = np.sqrt(local_mean_sq - local_mean**2)\n",
    "\n",
    "    # Save result\n",
    "    out_ds = driver.Create(output_path, ds.RasterXSize, ds.RasterYSize, 1, gdal.GDT_Float32,\n",
    "                           options=[\"COMPRESS=DEFLATE\", \"BIGTIFF=YES\"])\n",
    "    out_ds.SetGeoTransform(ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(ds.GetProjection())\n",
    "    out_ds.GetRasterBand(1).WriteArray(local_std)\n",
    "    out_ds.GetRasterBand(1).SetNoDataValue(np.nan)\n",
    "    out_ds.FlushCache()\n",
    "    out_ds = None\n",
    "\n",
    "    ds = None\n",
    "    print(f\"‚úÖ Saved local std image: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def nan_safe_mean_filter(values):\n",
    "    \"\"\"Computes the mean of non-NaN values.\"\"\"\n",
    "    valid_values = values[~np.isnan(values)]\n",
    "    return np.nan if valid_values.size == 0 else np.mean(valid_values)\n",
    "\n",
    "\n",
    "def compute_normprod(dog1, dog2, std1, std2, output_path, output_path_std, output_path_stdmean, window_size):\n",
    "    \"\"\"Computes Normalized Product (NormProd) using precomputed smoothed images, with NaN-safe summation.\"\"\"\n",
    "    print(\"In compute_normprod...\")\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"‚úÖ Skipping, {output_path} already exists.\")\n",
    "        return output_path\n",
    "\n",
    "    ds_dog1 = gdal.Open(dog1, gdal.GA_ReadOnly)\n",
    "    ds_dog2 = gdal.Open(dog2, gdal.GA_ReadOnly)\n",
    "    ds_std1 = gdal.Open(std1, gdal.GA_ReadOnly)\n",
    "    ds_std2 = gdal.Open(std2, gdal.GA_ReadOnly)\n",
    "\n",
    "    if not all([ds_dog1, ds_dog2, ds_std1, ds_std2]):\n",
    "        print(f\"‚ùå ERROR: Missing input files.\")\n",
    "        return None\n",
    "\n",
    "    driver = gdal.GetDriverByName(\"GTIFF\")\n",
    "\n",
    "    print(\"Reading these in..\")\n",
    "    # Read the single-band rasters\n",
    "    dog1 = ds_dog1.GetRasterBand(1).ReadAsArray()\n",
    "    dog2 = ds_dog2.GetRasterBand(1).ReadAsArray()\n",
    "    std1 = ds_std1.GetRasterBand(1).ReadAsArray()\n",
    "    std2 = ds_std2.GetRasterBand(1).ReadAsArray()    \n",
    "\n",
    "    # Mean the two stds together (to start with. GABBY you might have better ideas?)\n",
    "    stdmean = np.mean(np.stack([std1, std2], axis=0), axis=0)\n",
    "    \n",
    "    print(\"Saving StdMean...\")\n",
    "    # Save output\n",
    "    out_ds = driver.Create(output_path_stdmean, ds_dog1.RasterXSize, ds_dog1.RasterYSize, 1, gdal.GDT_Float32,\n",
    "                           options=[\"COMPRESS=DEFLATE\", \"BIGTIFF=YES\"])\n",
    "    out_ds.SetGeoTransform(ds_dog1.GetGeoTransform())\n",
    "    out_ds.SetProjection(ds_dog1.GetProjection())\n",
    "    out_ds.GetRasterBand(1).WriteArray(stdmean)\n",
    "    out_ds.GetRasterBand(1).SetNoDataValue(np.nan)\n",
    "    out_ds.FlushCache()\n",
    "    out_ds = None\n",
    "\n",
    "    print(\"Computing the actual normprod...\")\n",
    "    # Compute NormProd: (Im1 - smooth(Im1)) * (Im2 - smooth(Im2))\n",
    "    normprod = dog1 * dog2\n",
    "\n",
    "\n",
    "    print(\"Computing the sum of DoG1*DoG2 within small windows\")\n",
    "    # Apply a NaN-safe summation using generic_filter\n",
    "    footprint = np.ones((window_size, window_size))  # Window for summation\n",
    "    print(\"Starting generic_filter... about 10 mins for 11*11, 12 mins for 21*21.\")\n",
    "    #pdb.set_trace()\n",
    "    summed_normprod = generic_filter(normprod, nan_safe_mean_filter, footprint=footprint, mode='constant', cval=np.nan)\n",
    "    print(\"Finished generic_filter\")\n",
    "    \n",
    "    print(\"Saving output...\")\n",
    "    # Save output\n",
    "    out_ds = driver.Create(output_path, ds_dog1.RasterXSize, ds_dog1.RasterYSize, 1, gdal.GDT_Float32,\n",
    "                           options=[\"COMPRESS=DEFLATE\", \"BIGTIFF=YES\"])\n",
    "    out_ds.SetGeoTransform(ds_dog1.GetGeoTransform())\n",
    "    out_ds.SetProjection(ds_dog1.GetProjection())\n",
    "    out_ds.GetRasterBand(1).WriteArray(summed_normprod)\n",
    "    out_ds.GetRasterBand(1).SetNoDataValue(np.nan)\n",
    "    out_ds.FlushCache()\n",
    "    out_ds = None\n",
    "\n",
    "    # Now also write out the divide-by-stdmean one....\n",
    "    out_ds = driver.Create(output_path_std, ds_dog1.RasterXSize, ds_dog1.RasterYSize, 1, gdal.GDT_Float32,\n",
    "                           options=[\"COMPRESS=DEFLATE\", \"BIGTIFF=YES\"])\n",
    "    out_ds.SetGeoTransform(ds_dog1.GetGeoTransform())\n",
    "    out_ds.SetProjection(ds_dog1.GetProjection())\n",
    "    out_ds.GetRasterBand(1).WriteArray(summed_normprod/stdmean)\n",
    "    out_ds.GetRasterBand(1).SetNoDataValue(np.nan)\n",
    "    out_ds.FlushCache()\n",
    "    out_ds = None\n",
    "\n",
    "    print(\"Freeing memory...\")\n",
    "    ds_dog1, ds_dog2, normprod, summed_normprod, stdmean = None, None, None, None, None\n",
    "    print(f\"‚úÖ Saved NormProd (and STD) image: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def process_image_pair(imPair, localDataDir, outputEPSG):\n",
    "    \"\"\"Processes an image pair to compute DoG and Normalized Product (NormProd).\"\"\"\n",
    "    base1, base2 = base_filenames[imPair[0]], base_filenames[imPair[1]]\n",
    "    Date1, Date2 = base1[12:20], base2[12:20]\n",
    "    \n",
    "    # KEEPING compareFold unchanged\n",
    "    compareFold = os.path.join(localDataDir, f\"ISCE3_NormProd_EW_{Date1}_{Date2}\")\n",
    "\n",
    "    georeg1 = os.path.join(compareFold, f\"georeg_1_{Date1}_EPSG{outputEPSG}.tif\")\n",
    "    georeg2 = os.path.join(compareFold, f\"georeg_2_{Date2}_EPSG{outputEPSG}.tif\")\n",
    "\n",
    "    if not (os.path.exists(georeg1) and os.path.exists(georeg2)):\n",
    "        print(f\"‚ùå Skipping pair {imPair}: missing input files.\")\n",
    "        return\n",
    "\n",
    "    for sigma in windows:\n",
    "        print(f\"üöÄ Processing DoG and NormProd with Gaussian smoothing sigma={sigma}\")\n",
    "\n",
    "        # Compute DoG images\n",
    "        dog1_output = os.path.join(compareFold, f\"DoG_{sigma}_EPSG{outputEPSG}_{Date1}.tif\")\n",
    "        dog2_output = os.path.join(compareFold, f\"DoG_{sigma}_EPSG{outputEPSG}_{Date2}.tif\")\n",
    "\n",
    "        # DoGs weren't good, boxcar was much better.\n",
    "        #compute_dog(georeg1, dog1_output, sigma)\n",
    "        #compute_dog(georeg2, dog2_output, sigma)\n",
    "        compute_boxcar_diff(georeg1, dog1_output, sigma)\n",
    "        compute_boxcar_diff(georeg2, dog2_output, sigma)\n",
    "\n",
    "        # Also need to compute the sigmas in here too...\n",
    "        std1_output = os.path.join(compareFold, f\"STD_{sigma}_EPSG{outputEPSG}_{Date1}.tif\")\n",
    "        std2_output = os.path.join(compareFold, f\"STD_{sigma}_EPSG{outputEPSG}_{Date2}.tif\")\n",
    "        compute_local_std(georeg1, std1_output, sigma)\n",
    "        compute_local_std(georeg2, std2_output, sigma)\n",
    "\n",
    "        print(\"Happy with the filtering, and have made the STDs. Starting normprod...\")\n",
    "\n",
    "        # Compute Normalized Product (NormProd)\n",
    "        normprod_output = os.path.join(compareFold, f\"NormProd_{sigma}_EPSG{outputEPSG}_{Date1}_{Date2}.tif\")\n",
    "        normprod_std_output = os.path.join(compareFold, f\"NormProdStd_{sigma}_EPSG{outputEPSG}_{Date1}_{Date2}.tif\")\n",
    "        std_output = os.path.join(compareFold, f\"StdMean_{sigma}_EPSG{outputEPSG}_{Date1}_{Date2}.tif\")\n",
    "        compute_normprod(dog1_output, dog2_output, std1_output, std2_output, normprod_output, normprod_std_output, std_output, sigma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7e5a629-cfc6-4b76-9a07-c09a58b018ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154347451.gadi-pbs\n"
     ]
    }
   ],
   "source": [
    "#Normprod 1.4. Qsub \n",
    "\n",
    "outputEPSG = 3031\n",
    "\n",
    "#YOUR ipynb DIRECTORY\n",
    "os.chdir('/g/data/jk72/gb4219/honours/normprod_standalone/')\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Directory to store PBS scripts and helper script\n",
    "script_dir = os.path.join(cwd, \"pbs_jobs\")\n",
    "os.makedirs(script_dir, exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "# GABBY YOU WILL HAVE TO CHANGE THE SOURCE PATH BELOW\n",
    "pbs_template = \"\"\"#!/bin/bash\n",
    "#PBS -P jk72\n",
    "#PBS -q normal\n",
    "#PBS -l walltime=03:00:00\n",
    "#PBS -l mem=24GB\n",
    "#PBS -l ncpus=2\n",
    "#PBS -l wd\n",
    "#PBS -l storage=gdata/fj7+scratch/jk72+gdata/jk72+gdata/yp75\n",
    "#PBS -N img_{jobname}\n",
    "#PBS -o logs/{jobname}.o\n",
    "#PBS -e logs/{jobname}.e\n",
    "\n",
    "source /g/data/jk72/gb4219/miniconda3_gabby/etc/profile.d/conda.sh\n",
    "conda activate fastice\n",
    "\n",
    "python3 {run_script_path} \"{base1}\" \"{base2}\" \"{local_data_dir}\" \"{epsg}\" \"{windows}\"\n",
    "\"\"\"\n",
    "\n",
    "# Write the helper script into script_dir\n",
    "run_script_path = os.path.join(script_dir, \"run_single_pair.py\")\n",
    "with open(run_script_path, \"w\") as f:\n",
    "    f.write(\"\"\"\\\n",
    "import sys\n",
    "import ast\n",
    "from process_image_pairs import process_image_pair, compute_normprod, nan_safe_mean_filter, compute_local_std, compute_boxcar_diff, compute_dog, fill_nans, check_raster_stats, cleanup_intermediate_files\n",
    "\n",
    "base1 = sys.argv[1]\n",
    "base2 = sys.argv[2]\n",
    "data_dir = sys.argv[3]\n",
    "epsg = int(sys.argv[4])\n",
    "windows = ast.literal_eval(sys.argv[5])\n",
    "\n",
    "process_image_pair(base1, base2, data_dir, epsg, windows)\n",
    "\"\"\")\n",
    "\n",
    "# Loop through image pairs and submit each one\n",
    "for i, imPair in enumerate(allPairs):\n",
    "    jobname = f\"pair_{i}\"\n",
    "\n",
    "    pbs_script_path = os.path.join(script_dir, f\"job_{jobname}.pbs\")\n",
    "    with open(pbs_script_path, \"w\") as f:\n",
    "        f.write(pbs_template.format(\n",
    "            jobname=jobname,\n",
    "            base1=base_filenames[imPair[0]],\n",
    "            base2=base_filenames[imPair[1]],\n",
    "            local_data_dir=localDataDir,\n",
    "            epsg=outputEPSG,\n",
    "            windows=windows,\n",
    "            run_script_path=run_script_path\n",
    "        ))\n",
    "\n",
    "    # Uncomment if you want to debug interactively before submission\n",
    "    # pdb.set_trace()\n",
    "\n",
    "    subprocess.run([\"qsub\", pbs_script_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7746a-e6f1-4fb1-9807-26fe9adebf86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
